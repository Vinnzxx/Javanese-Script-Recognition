{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d07588c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inception_v3 (Functional)   (None, 1, 1, 2048)        21802784  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              2098176   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               131200    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               33024     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 512)               131584    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 20)                10260     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24207028 (92.34 MB)\n",
      "Trainable params: 2404244 (9.17 MB)\n",
      "Non-trainable params: 21802784 (83.17 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "Data = \"C:/Users/USER/Project10/Dataset/train\"\n",
    "Categories = [\"ba\", \"ca\", \"da\", \"dha\", \"ga\", \"ha\", \"ja\", \"ka\", \"la\", \"ma\", \"na\", \"nga\", \"nya\", \"pa\", \"ra\", \"sa\", \"ta\", \"tha\", \"wa\", \"ya\"]\n",
    "\n",
    "img_size = 100\n",
    "\n",
    "# Function to create training data\n",
    "def create_training_data():\n",
    "    training_data = []\n",
    "    for CATEGORY in Categories:\n",
    "        path = os.path.join(Data, CATEGORY)\n",
    "        class_num = Categories.index(CATEGORY)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_COLOR)  # Use IMREAD_COLOR for RGB images\n",
    "                img_array = cv2.resize(img_array, (img_size, img_size))\n",
    "                inverted_img_array = 255 - img_array  # Invert the colors\n",
    "                training_data.append([inverted_img_array, class_num])\n",
    "            except Exception as e:\n",
    "                pass\n",
    "    random.shuffle(training_data)\n",
    "    return training_data\n",
    "\n",
    "training_data = create_training_data()\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "for features, label in training_data:\n",
    "    x.append(features)\n",
    "    y.append(label)\n",
    "\n",
    "x = np.array(x).reshape(-1, img_size, img_size, 3)  # Use 3 channels for RGB images\n",
    "\n",
    "# Normalize and one-hot encode the labels\n",
    "x = x / 255.0\n",
    "y = to_categorical(y, num_classes=len(Categories))\n",
    "\n",
    "# Split data into 80% training and 20% testing\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Further split training data into 70% training and 10% validation\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.1, random_state=42)\n",
    "\n",
    "# Load the pre-trained InceptionV3 model without the top (fully connected) layers\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(img_size, img_size, 3))\n",
    "\n",
    "# Freeze the base model's layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Create your own classifier (top layers)\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation=\"relu\"))\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dense(256, activation=\"relu\"))\n",
    "model.add(Dense(512, activation=\"relu\"))\n",
    "model.add(Dense(len(Categories), activation=\"softmax\"))  # Use softmax activation for multiclass classification\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b134876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " densenet121 (Functional)    (None, 3, 3, 1024)        7037504   \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 9216)              0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 128)               1179776   \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 256)               33024     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 512)               131584    \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1024)              525312    \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 20)                20500     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8927700 (34.06 MB)\n",
      "Trainable params: 1890196 (7.21 MB)\n",
      "Non-trainable params: 7037504 (26.85 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "Data = \"C:/Users/USER/Project10/Dataset/train\"\n",
    "Categories = [\"ba\", \"ca\", \"da\", \"dha\", \"ga\", \"ha\", \"ja\", \"ka\", \"la\", \"ma\", \"na\", \"nga\", \"nya\", \"pa\", \"ra\", \"sa\", \"ta\", \"tha\", \"wa\", \"ya\"]\n",
    "\n",
    "img_size = 100\n",
    "\n",
    "# Function to create training data\n",
    "def create_training_data():\n",
    "    training_data = []\n",
    "    for CATEGORY in Categories:\n",
    "        path = os.path.join(Data, CATEGORY)\n",
    "        class_num = Categories.index(CATEGORY)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_COLOR)  # Use IMREAD_COLOR for RGB images\n",
    "                img_array = cv2.resize(img_array, (img_size, img_size))\n",
    "                inverted_img_array = 255 - img_array  # Invert the colors\n",
    "                training_data.append([inverted_img_array, class_num])\n",
    "            except Exception as e:\n",
    "                pass\n",
    "    random.shuffle(training_data)\n",
    "    return training_data\n",
    "\n",
    "training_data = create_training_data()\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "for features, label in training_data:\n",
    "    x.append(features)\n",
    "    y.append(label)\n",
    "\n",
    "x = np.array(x).reshape(-1, img_size, img_size, 3)  # Use 3 channels for RGB images\n",
    "\n",
    "# Normalize and one-hot encode the labels\n",
    "x = x / 255.0\n",
    "y = to_categorical(y, num_classes=len(Categories))\n",
    "\n",
    "# Split data into 80% training and 20% testing\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Further split training data into 70% training and 10% validation\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.1, random_state=42)\n",
    "\n",
    "# Load the pre-trained DenseNet121 model without the top layers\n",
    "base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(img_size, img_size, 3))\n",
    "\n",
    "# Freeze the base model's layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Create your own classifier (top layers)\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "\n",
    "# Change the output layer to match the number of classes\n",
    "model.add(Dense(len(Categories), activation='softmax'))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a362d6ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50 (Functional)       (None, 4, 4, 2048)        23587712  \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 32768)             0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 512)               16777728  \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1024)              525312    \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 256)               262400    \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 20)                2580      \n",
      "                                                                 \n",
      " activation_94 (Activation)  (None, 20)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 41188628 (157.12 MB)\n",
      "Trainable params: 17600916 (67.14 MB)\n",
      "Non-trainable params: 23587712 (89.98 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Data = \"C:/Users/USER/Project10/Dataset/train\"\n",
    "Categories = [\"ba\", \"ca\", \"da\", \"dha\", \"ga\", \"ha\", \"ja\", \"ka\", \"la\", \"ma\", \"na\", \"nga\", \"nya\", \"pa\", \"ra\", \"sa\", \"ta\", \"tha\", \"wa\", \"ya\"]\n",
    "\n",
    "img_size = 100\n",
    "\n",
    "def create_training_data():\n",
    "    training_data = []\n",
    "    for CATEGORY in Categories:\n",
    "        path = os.path.join(Data, CATEGORY)\n",
    "        class_num = Categories.index(CATEGORY)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_COLOR)\n",
    "                img_array = cv2.resize(img_array, (img_size, img_size))\n",
    "                inverted_img_array = 255 - img_array\n",
    "                training_data.append([inverted_img_array, class_num])\n",
    "            except Exception as e:\n",
    "                pass\n",
    "    random.shuffle(training_data)\n",
    "    return training_data\n",
    "\n",
    "training_data = create_training_data()\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "for features, label in training_data:\n",
    "    x.append(features)\n",
    "    y.append(label)\n",
    "\n",
    "x = np.array(x).reshape(-1, img_size, img_size, 3)\n",
    "x = x / 255.0\n",
    "y = to_categorical(y, num_classes=len(Categories))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.1, random_state=42)\n",
    "\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(img_size, img_size, 3))\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Load the pre-trained ResNet50 model without the top (fully connected) layers\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(img_size, img_size, 3))\n",
    "\n",
    "# Freeze the base model's layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Create your own classifier (top layers)\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add dense layers for classification\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "# Change the output layer to match the number of classes\n",
    "model.add(Dense(len(Categories)))\n",
    "model.add(Activation(\"softmax\"))  # Use softmax activation for multiclass classification\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfd11459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg16 (Functional)          (None, 3, 3, 512)         14714688  \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 4608)              0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 512)               2359808   \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 20)                2580      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17241300 (65.77 MB)\n",
      "Trainable params: 2526612 (9.64 MB)\n",
      "Non-trainable params: 14714688 (56.13 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "Data = \"C:/Users/USER/Project10/Dataset/train\"\n",
    "Categories = [\"ba\", \"ca\", \"da\", \"dha\", \"ga\", \"ha\", \"ja\", \"ka\", \"la\", \"ma\", \"na\", \"nga\", \"nya\", \"pa\", \"ra\", \"sa\", \"ta\", \"tha\", \"wa\", \"ya\"]\n",
    "\n",
    "img_size = 100\n",
    "\n",
    "# Function to create training data\n",
    "def create_training_data():\n",
    "    training_data = []\n",
    "    for CATEGORY in Categories:\n",
    "        path = os.path.join(Data, CATEGORY)\n",
    "        class_num = Categories.index(CATEGORY)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_COLOR)  # Use IMREAD_COLOR for RGB images\n",
    "                img_array = cv2.resize(img_array, (img_size, img_size))\n",
    "                inverted_img_array = 255 - img_array  # Invert the colors\n",
    "                training_data.append([inverted_img_array, class_num])\n",
    "            except Exception as e:\n",
    "                pass\n",
    "    random.shuffle(training_data)\n",
    "    return training_data\n",
    "\n",
    "training_data = create_training_data()\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "for features, label in training_data:\n",
    "    x.append(features)\n",
    "    y.append(label)\n",
    "\n",
    "x = np.array(x).reshape(-1, img_size, img_size, 3)  # Use 3 channels for RGB images\n",
    "\n",
    "# Normalize and one-hot encode the labels\n",
    "x = x / 255.0\n",
    "y = to_categorical(y, num_classes=len(Categories))\n",
    "\n",
    "# Split data into 80% training and 20% testing\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Further split training data into 70% training and 10% validation\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.1, random_state=42)\n",
    "\n",
    "# Load the pre-trained VGG16 model without the top (fully connected) layers\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(img_size, img_size, 3))\n",
    "\n",
    "# Freeze the base model's layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Create your own classifier (top layers)\n",
    "model = Sequential()\n",
    "model.add(base_model)  # Add the VGG16 base model\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))  # Custom dense layer\n",
    "model.add(Dense(256, activation='relu'))  # Another custom dense layer\n",
    "model.add(Dense(128, activation='relu'))  # Another custom dense layer\n",
    "model.add(Dense(len(Categories), activation='softmax'))  # Output layer\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7c5c405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg19 (Functional)          (None, 3, 3, 512)         20024384  \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 4608)              0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 512)               2359808   \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 20)                2580      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22550996 (86.03 MB)\n",
      "Trainable params: 2526612 (9.64 MB)\n",
      "Non-trainable params: 20024384 (76.39 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "Data = \"C:/Users/USER/Project10/Dataset/train\"\n",
    "Categories = [\"ba\", \"ca\", \"da\", \"dha\", \"ga\", \"ha\", \"ja\", \"ka\", \"la\", \"ma\", \"na\", \"nga\", \"nya\", \"pa\", \"ra\", \"sa\", \"ta\", \"tha\", \"wa\", \"ya\"]\n",
    "\n",
    "img_size = 100\n",
    "\n",
    "# Function to create training data\n",
    "def create_training_data():\n",
    "    training_data = []\n",
    "    for CATEGORY in Categories:\n",
    "        path = os.path.join(Data, CATEGORY)\n",
    "        class_num = Categories.index(CATEGORY)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_COLOR)  # Use IMREAD_COLOR for RGB images\n",
    "                img_array = cv2.resize(img_array, (img_size, img_size))\n",
    "                inverted_img_array = 255 - img_array  # Invert the colors\n",
    "                training_data.append([inverted_img_array, class_num])\n",
    "            except Exception as e:\n",
    "                pass\n",
    "    random.shuffle(training_data)\n",
    "    return training_data\n",
    "\n",
    "training_data = create_training_data()\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "for features, label in training_data:\n",
    "    x.append(features)\n",
    "    y.append(label)\n",
    "\n",
    "x = np.array(x).reshape(-1, img_size, img_size, 3)  # Use 3 channels for RGB images\n",
    "\n",
    "# Normalize and one-hot encode the labels\n",
    "x = x / 255.0\n",
    "y = to_categorical(y, num_classes=len(Categories))\n",
    "\n",
    "# Split data into 80% training and 20% testing\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Further split training data into 70% training and 10% validation\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.1, random_state=42)\n",
    "\n",
    "# Load the pre-trained VGG16 model without the top (fully connected) layers\n",
    "base_model = VGG19(weights='imagenet', include_top=False, input_shape=(img_size, img_size, 3))\n",
    "\n",
    "# Freeze the base model's layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Create your own classifier (top layers)\n",
    "model = Sequential()\n",
    "model.add(base_model)  # Add the VGG16 base model\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))  # Custom dense layer\n",
    "model.add(Dense(256, activation='relu'))  # Another custom dense layer\n",
    "model.add(Dense(128, activation='relu'))  # Another custom dense layer\n",
    "model.add(Dense(len(Categories), activation='softmax'))  # Output layer\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1515013",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
